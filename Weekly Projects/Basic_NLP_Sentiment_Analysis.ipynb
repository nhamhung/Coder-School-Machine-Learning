{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Basic NLP-Sentiment Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhamhung/Coder-School-Machine-Learning/blob/master/Basic_NLP_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LyU_yrP9Owx7"
      },
      "source": [
        "## Sentiment Analysis with Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uAzG2re1PtV0"
      },
      "source": [
        "This dataset is from a real contest of Text Processing.\n",
        "\n",
        "The task is to build a model that will determine the tone (positive, negative) of the text. To do this, you will need to train the model on the existing data (train.csv). The resulting model will have to determine the class (neutral, positive, negative) of new texts. The dataset contains the following fields:\n",
        "\n",
        "| Field name | Meaning |\n",
        "|------------|-----------|\n",
        "| ItemID  | id of twit|\n",
        "| Sentiment | sentiment (1-positive, 0-negative)|\n",
        "| SentimentText | text of the twit|\n",
        "\n",
        "Let's first of all have a look at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62WfvUYWe8-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "464183ca-724a-442f-c319-1ae9b0cddb5b"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SvME2ywsO0Nx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "a047e0a3-2977-4be8-a222-10f7db4166b3"
      },
      "source": [
        "sentiment = pd.read_csv('https://raw.githubusercontent.com/dhminh1024/practice_datasets/master/twitter_sentiment_analysis.csv', encoding='latin-1')\n",
        "sentiment.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ItemID</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75294</th>\n",
              "      <td>75306</td>\n",
              "      <td>1</td>\n",
              "      <td>@BttrflyV69 good!! i'm good at something i see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77790</th>\n",
              "      <td>77802</td>\n",
              "      <td>0</td>\n",
              "      <td>@aquascorpio Wish I could have seen it, but di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33669</th>\n",
              "      <td>33681</td>\n",
              "      <td>0</td>\n",
              "      <td>@aini training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65605</th>\n",
              "      <td>65617</td>\n",
              "      <td>1</td>\n",
              "      <td>@BrentSpiner  safe to say that star trek next ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93205</th>\n",
              "      <td>93217</td>\n",
              "      <td>1</td>\n",
              "      <td>@connoraa omg, I love that song</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ItemID  Sentiment                                      SentimentText\n",
              "75294   75306          1  @BttrflyV69 good!! i'm good at something i see...\n",
              "77790   77802          0  @aquascorpio Wish I could have seen it, but di...\n",
              "33669   33681          0                                    @aini training \n",
              "65605   65617          1  @BrentSpiner  safe to say that star trek next ...\n",
              "93205   93217          1                   @connoraa omg, I love that song "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UdJgPnccP13V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "68c1e904-43ba-40ca-b4c5-a70d00356206"
      },
      "source": [
        "sentiment.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99989 entries, 0 to 99988\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   ItemID         99989 non-null  int64 \n",
            " 1   Sentiment      99989 non-null  int64 \n",
            " 2   SentimentText  99989 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 2.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0eyPS4qgQTUr"
      },
      "source": [
        "As we can see, the structure of a twit varies a lot between twit and twit. They have different lengths, letters, numbers, strange characters, etc. \n",
        "\n",
        "It is also important to note that **a lot** of words are not correctly spelled, for example, the word _\"Juuuuuuuuuuuuuuuuussssst\"_ or the word _\"sooo\"_\n",
        "\n",
        "This makes it hard to measure how positive or negative the words are within the twits.\n",
        "\n",
        "So we need a way of scoring the words such that words that appear in positive twits have a greater score than those that appear in negative twits.\n",
        "\n",
        "But first, how do we represent the twits as vectors we can input to our algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SMz35YKYRd-R"
      },
      "source": [
        "### Bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JDA6FfQORhF1"
      },
      "source": [
        "One thing we could do to represent the twits as equal-sized vectors of numbers is the following:\n",
        "\n",
        "* Create a list (vocabulary) with all the unique words in the whole corpus of twits. \n",
        "* We construct a feature vector from each twit that contains the counts of how often each word occurs in the particular twit\n",
        "\n",
        "_Note that since the unique words in each twit represent only a small subset of all the words in the bag-of-words vocabulary, the feature vectors will mostly consist of zeros_\n",
        "\n",
        "Let's construct the bag of words. We will work with a smaller example for illustrative purposes, and in the end, we will work with our real data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H7m-TF9FQKP3",
        "colab": {}
      },
      "source": [
        "twits = [\n",
        "    'This is amazing!',\n",
        "    'ML is the best, yes it is',\n",
        "    'I am not sure about how this is going to end...'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cXxKR5dVRq_O"
      },
      "source": [
        "Let's import [CountVectorizer.](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) It'll help us to convert a collection of text documents to a matrix of token counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_i8bn8EoRoeB",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Define an object of CountVectorizer() fit and transfom your twits into a 'bag'\n",
        "count = CountVectorizer()\n",
        "bag = count.fit_transform(twits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b7RRV-gYR1yv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "42593e84-b275-4ee5-a9f4-c092569cbe1a"
      },
      "source": [
        "# Find in document of CountVectorizer a function that show us list of feature names\n",
        "count.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['about',\n",
              " 'am',\n",
              " 'amazing',\n",
              " 'best',\n",
              " 'end',\n",
              " 'going',\n",
              " 'how',\n",
              " 'is',\n",
              " 'it',\n",
              " 'ml',\n",
              " 'not',\n",
              " 'sure',\n",
              " 'the',\n",
              " 'this',\n",
              " 'to',\n",
              " 'yes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rAzAWM0gR5E6"
      },
      "source": [
        "As we can see from executing the preceding command, the vocabulary is stored in a Python array that maps the unique words to integer indices. Next, let's print the feature vectors that we just created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B2opUD9OR5lD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "bc64b13a-5447-4f10-cf60-c7d2170ab01b"
      },
      "source": [
        "# Call toarray() on your 'bag' to see the feature vectors\n",
        "bag.toarray()\n",
        "twits = [\n",
        "    'This is amazing!',\n",
        "    'ML is the best, yes it is',\n",
        "    'I am not sure about how this is going to end...'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 1],\n",
              "       [1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VifgJzQuSAlO"
      },
      "source": [
        "**Quiz**: What is the index of the word 'is' and how many times it occurs in all three twits?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0fPGxGk9Se0G"
      },
      "source": [
        "Each index position in the feature vectors corresponds to the integer values that are stored as dictionary items in the CountVectorizer vocabulary. For example, the first feature at index position 0 resembles the count of the word 'about', which only occurs in the last document. These values in the feature vectors are also called the **raw term frequencies**: `tf(t,d )` —the number of times a term `t` occurs in a document `d`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KXxo5MKETMpB"
      },
      "source": [
        "### How relevant are words? Term frequency-inverse document frequency\n",
        "\n",
        "We could use these raw term frequencies to score the words in our algorithm. There is a problem though: If a word is widespread in _all_ documents, then it probably doesn't carry a lot of information. To tackle this problem, we can use **term frequency-inverse document frequency**, which will reduce the score, the more frequent the word is across all twits. It is calculated like this:\n",
        "\n",
        "\\begin{equation*}\n",
        "tf-idf(t,d) = tf(t,d) ~ idf(t,d)\n",
        "\\end{equation*}\n",
        "\n",
        "_tf(t,d)_ is the raw term frequency descrived above. _idf(t,d)_ is the inverse document frequency, than can be calculated as follows:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\log \\frac{n_d}{1+df\\left(d,t\\right)}\n",
        "\\end{equation*}\n",
        "\n",
        "Where `n` is the total number of documents, and _df(t,d)_ is the number of documents where the term `t` appears. \n",
        "\n",
        "The `1` addition in the denominator is just to avoid zero terms for terms that appear in all documents, will not be entirely ignored. And the `log` ensures that low-frequency term doesn't get too much weight.\n",
        "\n",
        "Fortunately for us, `scikit-learn` does all those calculations for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONWZkDBiu7oJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "47896d10-3b73-4642-e421-815a2882841d"
      },
      "source": [
        "# idf(t) = log [ n / df(t) ] + 1 \n",
        "n = 3\n",
        "print('amazing', np.log(n/1) + 1)\n",
        "print('is', np.log(n/3) + 1)\n",
        "print('this', np.log(n/2) + 1)\n",
        "\n",
        "a = np.array([np.log(n/1) + 1, np.log(n/3) + 1, np.log(n/2) + 1])\n",
        "a/a.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "amazing 2.09861228866811\n",
            "is 1.0\n",
            "this 1.4054651081081644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.47, 0.22, 0.31])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Ubq0BVJSgb-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b5acf14e-6242-4316-aded-d2825e6653d4"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(norm='l1', smooth_idf=False)\n",
        "# Feed the tf-idf Vectorizer with twits using fit_transform()\n",
        "tfidf_vec = tfidf.fit_transform(twits)\n",
        "\n",
        "# Formatting the number to 2 digits after the decimal point by showing on this notebook\n",
        "np.set_printoptions(precision=2)\n",
        "# To print array in one line\n",
        "np.set_printoptions(linewidth=np.inf)\n",
        "print(tfidf.get_feature_names())\n",
        "print(tfidf_vec.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['about', 'am', 'amazing', 'best', 'end', 'going', 'how', 'is', 'it', 'ml', 'not', 'sure', 'the', 'this', 'to', 'yes']\n",
            "[[0.   0.   0.47 0.   0.   0.   0.   0.22 0.   0.   0.   0.   0.   0.31 0.   0.  ]\n",
            " [0.   0.   0.   0.17 0.   0.   0.   0.16 0.17 0.17 0.   0.   0.17 0.   0.   0.17]\n",
            " [0.11 0.11 0.   0.   0.11 0.11 0.11 0.05 0.   0.   0.11 0.11 0.   0.07 0.11 0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdHVn4VTu09l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JCoApsmLUIYJ"
      },
      "source": [
        "## Data cleaning and manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GU--SSvPUOKG"
      },
      "source": [
        "Let's work on our real vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pi8mjlxaUbpY"
      },
      "source": [
        "### Removing stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yc6q-9NbUuVO"
      },
      "source": [
        "**Stop words** are the most common words are meaningless in terms of sentiment: I, to, the, and... they don't give any information on positiveness or negativeness. They're basically noise that can most probably be eliminated. Therefore, it is a common practice to remove them when doing text analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y0SJA2wiTbGr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "17a78d2c-e119-41e2-9067-6e896ecbdff8"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "vocab = Counter()\n",
        "for twit in sentiment.SentimentText:\n",
        "    for word in twit.split(' '):\n",
        "        vocab[word] += 1\n",
        "\n",
        "vocab.most_common(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 123916),\n",
              " ('I', 32879),\n",
              " ('to', 28810),\n",
              " ('the', 28087),\n",
              " ('a', 21321),\n",
              " ('you', 21180),\n",
              " ('i', 15995),\n",
              " ('and', 14565),\n",
              " ('it', 12818),\n",
              " ('my', 12385),\n",
              " ('for', 12149),\n",
              " ('in', 11199),\n",
              " ('is', 11185),\n",
              " ('of', 10326),\n",
              " ('that', 9181),\n",
              " ('on', 9020),\n",
              " ('have', 8991),\n",
              " ('me', 8255),\n",
              " ('so', 7612),\n",
              " ('but', 7220)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CXn9PepUUtzB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "f0286685-4d6e-4638-c9c9-c7a98d5385e5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kri9m-4gVETb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "8df1a185-a79b-4d6c-a73c-0549eae299ae"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "vocab_reduced = Counter()\n",
        "# Go through all of the items of vocab using vocab.items() and pick only words that are not in 'stop_words' \n",
        "# and save them in vocab_reduced\n",
        "for w, c in vocab.items():\n",
        "    if not w in stop_words:\n",
        "        vocab_reduced[w]=c\n",
        "\n",
        "vocab_reduced.most_common(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 123916),\n",
              " ('I', 32879),\n",
              " (\"I'm\", 6416),\n",
              " ('like', 5086),\n",
              " ('-', 4922),\n",
              " ('get', 4864),\n",
              " ('u', 4194),\n",
              " ('good', 3953),\n",
              " ('love', 3494),\n",
              " ('know', 3472),\n",
              " ('go', 2990),\n",
              " ('see', 2868),\n",
              " ('one', 2787),\n",
              " ('got', 2774),\n",
              " ('think', 2613),\n",
              " ('&amp;', 2556),\n",
              " ('lol', 2419),\n",
              " ('going', 2396),\n",
              " ('really', 2287),\n",
              " ('im', 2200)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wZz4s9q-VWsb"
      },
      "source": [
        "### Removing special characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-n8CS-9uVle2"
      },
      "source": [
        "If you look closer, you'll see that we're also taking into consideration punctuation signs ('-', ',', etc) and other html tags like `&amp`. We can definitely remove them for the sentiment analysis, but we will try to keep the emoticons, since those _do_ have a sentiment load:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "slKWGWafVSQ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4be7afa8-1e0e-4397-f276-c62a6808ef4e"
      },
      "source": [
        "import re \n",
        "\n",
        "def preprocessor(text):\n",
        "    \"\"\" Return a cleaned version of text\n",
        "    \"\"\"\n",
        "    # Remove HTML markup\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    # Save emoticons for later appending\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    # Remove any non-word character and append the emoticons,\n",
        "    # removing the nose character for standarization. Convert to lower case\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Create some random texts for testing the function preprocessor()\n",
        "print(preprocessor('I like it :), |||<><>'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i like it  :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j2WTq9RgWEA7"
      },
      "source": [
        "### Stemming\n",
        "\n",
        "We are almost ready! There is another trick we can use to reduce our vocabulary and consolidate words. If you think about it, words like love, loving, etc. _Could_ express the same positivity. If that was the case, we would be having two words in our vocabulary when we could have only one: lov. This process of reducing a word to its root is called **stemming**.\n",
        "\n",
        "We also need a _tokenizer_ to break down our twits in individual words. We will implement two tokenizers, a regular one and one that does stemming:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-3B7XXLsVwtN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5b798fe8-3c25-409b-b69e-1880b4e056c8"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "# Split a text into list of words\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "# Split a text into list of words and apply stemming technic\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "\n",
        "# Testing\n",
        "print(tokenizer('Hi there, I am loving this, like with a lot of love'))\n",
        "print(tokenizer_porter('Hi there, I am loving this, like with a lot of love'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi', 'there,', 'I', 'am', 'loving', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n",
            "['Hi', 'there,', 'I', 'am', 'love', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vpx3O0lSWMRO"
      },
      "source": [
        "### Train Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pxiIwOffWOw-",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = sentiment['SentimentText']\n",
        "y = sentiment['Sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PIpejBPlWT7Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "cf59aec2-1de3-460a-907c-113a14cdb32e"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=stop_words,\n",
        "                        tokenizer=tokenizer_porter,\n",
        "                        preprocessor=preprocessor)\n",
        "\n",
        "# A pipeline is what chains several steps together, once the initial exploration is done. \n",
        "# For example, some codes are meant to transform features — normalise numericals, or turn text into vectors, \n",
        "# or fill up missing data, they are transformers; other codes are meant to predict variables by fitting an algorithm,\n",
        "# they are estimators. Pipeline chains all these together which can then be applied to training data\n",
        "clf = Pipeline([('vect', tfidf),\n",
        "                ('clf', LogisticRegression(random_state=0))])\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=<function preprocessor at 0x7f72c0501ae8>,\n",
              "                                 smooth_idf=True,\n",
              "                                 stop_words=['i', 'me', 'my', 'myself', '...\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenizer_porter at 0x7f72c04977b8>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=0,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kKz3ngEmWaq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "d7531b12-021f-4c68-e526-bd329a5b5564"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Now apply those above metrics to evaluate your model\n",
        "# Your code here\n",
        "predictions = clf.predict(X_test)\n",
        "print('accuracy:',accuracy_score(y_test,predictions))\n",
        "print('confusion matrix:\\n',confusion_matrix(y_test,predictions))\n",
        "print('classification report:\\n',classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.7525752575257526\n",
            "confusion matrix:\n",
            " [[5828 2877]\n",
            " [2071 9222]]\n",
            "classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.67      0.70      8705\n",
            "           1       0.76      0.82      0.79     11293\n",
            "\n",
            "    accuracy                           0.75     19998\n",
            "   macro avg       0.75      0.74      0.75     19998\n",
            "weighted avg       0.75      0.75      0.75     19998\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "70o0DCTtWm-9"
      },
      "source": [
        "Finally, let's run some tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vA7H4ZJrWdrY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "816145ed-d98a-413a-83f0-0f5faf345fb7"
      },
      "source": [
        "twits = [\n",
        "    \"I love bubble tea\", # 1\n",
        "    \"I hate calculus\", # 0\n",
        "    \"I don't know\", # 0.5\n",
        "    \"My name is love\", # 0.5\n",
        "    \"I love the way you lie\", # 1\n",
        "    \"Your song is killing me softly\" # 1\n",
        "]\n",
        "\n",
        "preds = clf.predict_proba(twits)\n",
        "\n",
        "for i in range(len(twits)):\n",
        "    print(f'{twits[i]} --> Negative, Positive = {preds[i]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I love bubble tea --> Negative, Positive = [0.16 0.84]\n",
            "I hate calculus --> Negative, Positive = [0.86 0.14]\n",
            "I don't know --> Negative, Positive = [0.43 0.57]\n",
            "My name is love --> Negative, Positive = [0.03 0.97]\n",
            "I love the way you lie --> Negative, Positive = [0.14 0.86]\n",
            "Your song is killing me softly --> Negative, Positive = [0.48 0.52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cm38nJbbWxfn"
      },
      "source": [
        "If we would like to use the classifier in another place, or just not train it again and again everytime, we can save the model in a pickle file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cKtYI_QaWrOj",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "pickle.dump(clf, open('logisticRegression.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F6dhu9N7Y3Jp"
      },
      "source": [
        "And reload it in your app:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1ePXZnQW2it",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "0a664e32-c583-4e03-992d-ece0220af566"
      },
      "source": [
        "with open('logisticRegression.pkl', 'rb') as model:\n",
        "    reload_model = pickle.load(model)\n",
        "preds = reload_model.predict_proba(twits)\n",
        "\n",
        "for i in range(len(twits)):\n",
        "    print(f'{twits[i]} --> Negative, Positive = {preds[i]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I love bubble tea --> Negative, Positive = [0.16 0.84]\n",
            "I hate calculus --> Negative, Positive = [0.86 0.14]\n",
            "I don't know --> Negative, Positive = [0.43 0.57]\n",
            "My name is love --> Negative, Positive = [0.03 0.97]\n",
            "I love the way you lie --> Negative, Positive = [0.14 0.86]\n",
            "Your song is killing me softly --> Negative, Positive = [0.48 0.52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a5G8-ZSjzdG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8b987d7-ee93-488e-cc5b-2392b9d4244e"
      },
      "source": [
        "stop_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UIj9GKy8Y9Pp"
      },
      "source": [
        "**Well done!**"
      ]
    }
  ]
}